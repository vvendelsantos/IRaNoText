import streamlit as st
import pandas as pd
import re
import io
import spacy
from word2number import w2n

# Carregar modelo do spaCy
nlp = spacy.load("pt_core_news_sm")

# ====================== CONFIGURA√á√ÉO DA P√ÅGINA ======================
st.set_page_config(
    page_title="Analisador de Texto Avan√ßado",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ====================== FUN√á√ïES AUXILIARES ======================
def detectar_siglas(texto):
    """Detecta siglas no texto (palavras com 2+ letras mai√∫sculas)"""
    tokens = re.findall(r"\b[A-Z]{2,}\b", texto)
    return sorted(set(tokens))

def detectar_palavras_compostas(texto):
    """Identifica palavras compostas usando o modelo de NER do spaCy"""
    doc = nlp(texto)
    compostas = [ent.text for ent in doc.ents if len(ent.text.split()) > 1]
    return list(set(compostas))

def estilo_pagina():
    """Aplica estilos CSS personalizados"""
    st.markdown("""
    <style>
        .stApp {
            background-color: #f9f9f9;
        }
        .stTextArea textarea {
            min-height: 200px;
        }
        .stButton>button {
            width: 100%;
            transition: all 0.3s ease;
        }
        .stButton>button:hover {
            transform: scale(1.02);
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 {
            color: #2c3e50;
        }
        .stTabs [data-baseweb="tab-list"] {
            gap: 10px;
        }
        .stTabs [data-baseweb="tab"] {
            padding: 10px 20px;
            border-radius: 8px 8px 0 0 !important;
        }
        .stAlert {
            border-radius: 8px;
        }
    </style>
    """, unsafe_allow_html=True)

# Aplicar estilos
estilo_pagina()

# ====================== LAYOUT PRINCIPAL ======================
st.title("üìä Analisador de Texto Avan√ßado")
st.markdown("""
    **Ferramenta para detec√ß√£o de siglas, palavras compostas e gera√ß√£o de corpus textual compat√≠vel com IRaMuTeQ**
""")

# ====================== ABAS PRINCIPAIS ======================
tab1, tab2 = st.tabs(["üìù Pr√©-an√°lise de Texto", "üìë Gera√ß√£o de Corpus"])

with tab1:
    # ====================== PARTE 1 - PR√â-AN√ÅLISE ======================
    st.header("üîç Detec√ß√£o de Siglas e Palavras Compostas")
    
    with st.expander("‚ÑπÔ∏è Sobre esta ferramenta", expanded=False):
        st.info("""
        Esta ferramenta identifica automaticamente:
        - **Siglas**: Palavras com 2 ou mais letras mai√∫sculas (ex: UFS, ONU)
        - **Palavras compostas**: Express√µes de m√∫ltiplas palavras que formam um conceito √∫nico (ex: ensino superior, intelig√™ncia artificial)
        """)
    
    texto_input = st.text_area(
        "‚úçÔ∏è Insira seu texto para an√°lise",
        height=250,
        placeholder="Cole ou digite seu texto aqui...",
        help="O texto ser√° analisado para detectar siglas e palavras compostas automaticamente"
    )
    
    if st.button("üîç Analisar Texto", type="primary", use_container_width=True):
        if texto_input.strip():
            with st.spinner("Processando texto..."):
                siglas = detectar_siglas(texto_input)
                compostas = detectar_palavras_compostas(texto_input)
            
            col1, col2 = st.columns(2, gap="large")
            
            with col1:
                st.subheader("üß© Palavras Compostas Detectadas")
                if compostas:
                    st.success(f"‚úÖ {len(compostas)} termo(s) encontrado(s)")
                    with st.container(border=True):
                        for termo in compostas:
                            st.markdown(f"- **{termo}**")
                else:
                    st.info("‚ÑπÔ∏è Nenhuma palavra composta encontrada.")
            
            with col2:
                st.subheader("üßæ Siglas Detectadas")
                if siglas:
                    st.success(f"‚úÖ {len(siglas)} sigla(s) encontrada(s)")
                    with st.container(border=True):
                        for sigla in siglas:
                            st.markdown(f"- **{sigla}**")
                else:
                    st.info("‚ÑπÔ∏è Nenhuma sigla encontrada.")
        else:
            st.warning("‚ö†Ô∏è Por favor, insira um texto antes de analisar.")

with tab2:
    # ====================== PARTE 2 - GERA√á√ÉO DE CORPUS ======================
    st.header("üìë Gerador de Corpus Textual para IRaMuTeQ")
    
    with st.expander("üìå Instru√ß√µes detalhadas", expanded=True):
        st.markdown("""
        ### Estrutura necess√°ria da planilha
        
        Para gerar o corpus corretamente, sua planilha Excel deve conter **3 abas** com os seguintes nomes:
        
        1. **`textos_selecionados`**: Textos que ser√£o processados (obrigat√≥rio ter coluna 'id')
        2. **`dic_palavras_compostas`**: Dicion√°rio de palavras compostas e suas formas normalizadas
        3. **`dic_siglas`**: Dicion√°rio de siglas e seus significados completos
        
        ### Processamento realizado
        
        - Normaliza√ß√£o de n√∫meros por extenso para algarismos
        - Tratamento de pronomes pospostos ("-se", "-lo", "-la", etc.)
        - Substitui√ß√£o de siglas por seus significados
        - Normaliza√ß√£o de palavras compostas
        - Remo√ß√£o/redu√ß√£o de caracteres especiais
        - Gera√ß√£o de metadados para cada texto
        """)
    
    # Bot√µes para download de modelos
    st.subheader("üì• Modelos para download")
    col_dl1, col_dl2 = st.columns(2)
    
    with col_dl1:
        with open("gerar_corpus_iramuteq.xlsx", "rb") as exemplo:
            st.download_button(
                label="üìã Baixar modelo de planilha",
                data=exemplo,
                file_name="modelo_corpus_iramuteq.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="Planilha modelo com a estrutura necess√°ria",
                use_container_width=True
            )
    
    with col_dl2:
        with open("textos_selecionados.xlsx", "rb") as textos:
            st.download_button(
                label="üìÇ Baixar textos exemplo",
                data=textos,
                file_name="textos_exemplo.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="Exemplo de textos para an√°lise",
                use_container_width=True
            )
    
    # Upload de arquivo
    st.subheader("üì§ Envie sua planilha")
    file = st.file_uploader(
        "Arraste e solte ou selecione seu arquivo Excel",
        type=["xlsx"],
        help="Planilha deve conter as 3 abas necess√°rias",
        label_visibility="collapsed"
    )
    
    # Fun√ß√µes auxiliares da parte 2
    def converter_numeros_por_extenso(texto):
        """Converte n√∫meros por extenso para algarismos num√©ricos"""
        try:
            return str(w2n.word_to_num(texto))
        except:
            return texto

    def processar_palavras_com_se(texto):
        """Trata pronomes 'se' pospostos"""
        return re.sub(r"(\b\w+)-se\b", r"se \1", texto)

    def processar_pronomes_pospostos(texto):
        """Trata v√°rios tipos de pronomes pospostos"""
        texto = re.sub(r'\b(\w+)-se\b', r'se \1', texto)
        texto = re.sub(r'\b(\w+)-([oa]s?)\b', r'\2 \1', texto)
        texto = re.sub(r'\b(\w+)-(lhe|lhes)\b', r'\2 \1', texto)
        texto = re.sub(r'\b(\w+)-(me|te|nos|vos)\b', r'\2 \1', texto)
        texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]?-([oa]s?)\b', r'\2 \1', texto)
        texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]-(lo|la|los|las)-ia\b', r'\2 \1ia', texto)
        return texto

    def gerar_corpus(df_textos, df_compostos, df_siglas):
        """Gera o corpus textual com base nas planilhas fornecidas"""
        dict_compostos = {
            str(row["Palavra composta"]).lower(): str(row["Palavra normalizada"]).lower()
            for _, row in df_compostos.iterrows()
            if pd.notna(row["Palavra composta"]) and pd.notna(row["Palavra normalizada"])
        }

        dict_siglas = {
            str(row["Sigla"]).lower(): str(row["Significado"])
            for _, row in df_siglas.iterrows()
            if pd.notna(row["Sigla"]) and pd.notna(row["Significado"])
        }

        caracteres_especiais = {
            "-": "H√≠fen", ";": "Ponto e v√≠rgula", '"': "Aspas duplas", "'": "Aspas simples",
            "‚Ä¶": "Retic√™ncias", "‚Äì": "Travess√£o", "(": "Par√™ntese esquerdo", ")": "Par√™ntese direito",
            "/": "Barra", "%": "Porcentagem"
        }
        
        contagem_caracteres = {k: 0 for k in caracteres_especiais}
        total_textos = 0
        total_siglas = 0
        total_compostos = 0
        total_remocoes = 0
        corpus_final = ""

        for _, row in df_textos.iterrows():
            texto = str(row.get("textos selecionados", ""))
            id_val = row.get("id", "")
            if not texto.strip():
                continue

            texto_corrigido = texto.lower()
            texto_corrigido = converter_numeros_por_extenso(texto_corrigido)
            texto_corrigido = processar_palavras_com_se(texto_corrigido)
            texto_corrigido = processar_pronomes_pospostos(texto_corrigido)
            total_textos += 1

            for sigla, significado in dict_siglas.items():
                texto_corrigido = re.sub(rf"\({sigla}\)", "", texto_corrigido)
                texto_corrigido = re.sub(rf"\b{sigla}\b", significado, texto_corrigido, flags=re.IGNORECASE)
                total_siglas += 1

            for termo, substituto in dict_compostos.items():
                if termo in texto_corrigido:
                    texto_corrigido = re.sub(rf"\b{termo}\b", substituto, texto_corrigido, flags=re.IGNORECASE)
                    total_compostos += 1

            for char in caracteres_especiais:
                count = texto_corrigido.count(char)
                if count:
                    if char == "%":
                        texto_corrigido = texto_corrigido.replace(char, "")
                    else:
                        texto_corrigido = texto_corrigido.replace(char, "_")
                    contagem_caracteres[char] += count
                    total_remocoes += count

            texto_corrigido = re.sub(r"\s+", " ", texto_corrigido.strip())

            metadata = f"**** *ID_{id_val}"
            for col in row.index:
                if col.lower() not in ["id", "textos selecionados"]:
                    metadata += f" *{col.replace(' ', '_')}_{str(row[col]).replace(' ', '_')}"

            corpus_final += f"{metadata}\n{texto_corrigido}\n"

        estatisticas = f"üìä Estat√≠sticas de Processamento\n{'='*30}\n"
        estatisticas += f"- Textos processados: {total_textos}\n"
        estatisticas += f"- Siglas substitu√≠das: {total_siglas}\n"
        estatisticas += f"- Palavras compostas normalizadas: {total_compostos}\n"
        estatisticas += f"- Caracteres especiais tratados: {total_remocoes}\n"
        for char, nome in caracteres_especiais.items():
            if contagem_caracteres[char] > 0:
                estatisticas += f"  - {nome} ({char}): {contagem_caracteres[char]}\n"

        return corpus_final, estatisticas

    if file:
        try:
            with st.spinner("Processando planilha..."):
                xls = pd.ExcelFile(file)
                df_textos = xls.parse("textos_selecionados")
                df_compostos = xls.parse("dic_palavras_compostas")
                df_siglas = xls.parse("dic_siglas")
                df_textos.columns = [col.strip().lower() for col in df_textos.columns]

            if st.button("üöÄ Gerar Corpus", type="primary", use_container_width=True):
                with st.spinner("Gerando corpus..."):
                    corpus, estatisticas = gerar_corpus(df_textos, df_compostos, df_siglas)

                if corpus.strip():
                    st.success("‚úÖ Corpus gerado com sucesso!")
                    
                    # Visualiza√ß√£o do corpus
                    st.subheader("üìÑ Pr√©-visualiza√ß√£o do Corpus")
                    with st.expander("Visualizar conte√∫do gerado", expanded=True):
                        st.text_area("", corpus, height=300, label_visibility="collapsed")
                    
                    # Estat√≠sticas
                    st.subheader("üìä M√©tricas do Processamento")
                    with st.container(border=True):
                        st.text(estatisticas)
                    
                    # Download do corpus
                    st.subheader("üì• Download do Corpus")
                    buf = io.BytesIO()
                    buf.write(corpus.encode("utf-8"))
                    st.download_button(
                        "üíæ Baixar Corpus Textual",
                        data=buf.getvalue(),
                        file_name="corpus_IRaMuTeQ.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                else:
                    st.warning("‚ö†Ô∏è Nenhum texto v√°lido encontrado na planilha.")

        except Exception as e:
            st.error(f"‚ùå Erro ao processar o arquivo: {str(e)}")
            st.info("Verifique se todas as abas necess√°rias est√£o presentes e no formato correto.")

# ====================== RODAP√â ======================
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.9em;">
    <p>üë®‚Äçüíª Desenvolvido por <strong>Jos√© Wendel dos Santos</strong></p>
    <p>üèõ Universidade Federal de Sergipe (UFS) | üìß eng.wendel@gmail.com</p>
</div>
""", unsafe_allow_html=True)
