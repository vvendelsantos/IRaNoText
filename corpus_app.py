import streamlit as st
import pandas as pd
import re
import io
from word2number import w2n

# Fun√ß√£o para converter n√∫meros por extenso para algarismos
def converter_numeros_por_extenso(texto):
    unidades = {
        "zero": 0, "dois": 2, "duas": 2, "tr√™s": 3, "quatro": 4, "cinco": 5,
        "seis": 6, "sete": 7, "oito": 8, "nove": 9
    }
    dezenas = {
        "dez": 10, "onze": 11, "doze": 12, "treze": 13, "quatorze": 14, "quinze": 15,
        "dezesseis": 16, "dezessete": 17, "dezoito": 18, "dezenove": 19, "vinte": 20
    }
    centenas = {
        "cem": 100, "cento": 100, "duzentos": 200, "trezentos": 300, "quatrocentos": 400,
        "quinhentos": 500, "seiscentos": 600, "setecentos": 700, "oitocentos": 800, "novecentos": 900
    }
    multiplicadores = {
        "mil": 1000, "milh√£o": 1000000, "milh√µes": 1000000, "bilh√£o": 1000000000,
        "bilh√µes": 1000000000
    }

    def processar_palavra(palavra):
        try:
            return str(w2n.word_to_num(palavra))
        except:
            return palavra

    palavras = texto.split()
    resultado = []
    for palavra in palavras:
        palavra_lower = palavra.lower()
        if palavra_lower in unidades:
            resultado.append(str(unidades[palavra_lower]))
        elif palavra_lower in dezenas:
            resultado.append(str(dezenas[palavra_lower]))
        elif palavra_lower in centenas:
            resultado.append(str(centenas[palavra_lower]))
        elif palavra_lower in multiplicadores:
            resultado.append(str(multiplicadores[palavra_lower]))
        else:
            resultado.append(processar_palavra(palavra))

    return " ".join(resultado)

# Fun√ß√£o para processar palavras compostas com "-se"
def processar_palavras_com_se(texto):
    return re.sub(r"(\b\w+)-se\b", r"se \1", texto)

# Fun√ß√£o para processar pronomes obl√≠quos p√≥s-verbais
def processar_pronomes_pospostos(texto):
    texto = re.sub(r'\b(\w+)-se\b', r'se \1', texto)
    texto = re.sub(r'\b(\w+)-([oa]s?)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)-(lhe|lhes)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)-(me|te|nos|vos)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]?-([oa]s?)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]-(lo|la|los|las)-ia\b', r'\2 \1ia', texto)
    return texto

# Fun√ß√£o para identificar palavras compostas a partir do texto, ignorando stopwords
def identificar_palavras_compostas(texto, stopwords):
    palavras = texto.split()
    palavras_compostas = set()

    for i in range(len(palavras) - 1):
        # Combinar palavras consecutivas, ignorando stopwords
        if palavras[i].lower() not in stopwords and palavras[i + 1].lower() not in stopwords:
            combinacao = f"{palavras[i]} {palavras[i + 1]}"
            palavras_compostas.add(combinacao)

    return palavras_compostas

# Fun√ß√£o ajustada para sugerir palavras compostas e siglas
def sugerir_palavras_compostas_e_siglas(texto, stopwords):
    # Identificar palavras compostas
    palavras_compostas = identificar_palavras_compostas(texto, stopwords)

    # Filtrar para n√£o sugerir palavras que j√° foram identificadas manualmente ou que s√£o irrelevantes
    palavras_compostas_relevantes = [p for p in palavras_compostas if len(p.split()) > 1 and p.lower() not in stopwords]

    return palavras_compostas_relevantes

# Fun√ß√£o principal ajustada
def gerar_corpus(df_textos, df_compostos, df_siglas, stopwords, texto_usuario=None):
    dict_compostos = {
        str(row["Palavra composta"]).lower(): str(row["Palavra normalizada"]).lower()
        for _, row in df_compostos.iterrows()
        if pd.notna(row["Palavra composta"]) and pd.notna(row["Palavra normalizada"])
    }

    dict_siglas = {
        str(row["Sigla"]).lower(): str(row["Significado"])
        for _, row in df_siglas.iterrows()
        if pd.notna(row["Sigla"]) and pd.notna(row["Significado"])
    }

    caracteres_especiais = {
        "-": "H√≠fen", ";": "Ponto e v√≠rgula", '"': "Aspas duplas", "'": "Aspas simples",
        "‚Ä¶": "Retic√™ncias", "‚Äì": "Travess√£o", "(": "Par√™ntese esquerdo", ")": "Par√™ntese direito",
        "/": "Barra", "%": "Porcentagem"
    }
    contagem_caracteres = {k: 0 for k in caracteres_especiais}
    total_textos = 0
    total_siglas = 0
    total_compostos = 0
    total_remocoes = 0
    corpus_final = ""

    # Usar o texto do usu√°rio ou processar a planilha
    if texto_usuario:
        texto = texto_usuario
        id_val = "user_text"
        if not texto.strip():
            return "", "Texto vazio."

        texto_corrigido = texto.lower()
        texto_corrigido = converter_numeros_por_extenso(texto_corrigido)
        texto_corrigido = processar_palavras_com_se(texto_corrigido)
        texto_corrigido = processar_pronomes_pospostos(texto_corrigido)
        total_textos += 1

        # Sugerir palavras compostas e filtrar stopwords
        palavras_compostas_relevantes = sugerir_palavras_compostas_e_siglas(texto_corrigido, stopwords)
        total_compostos += len(palavras_compostas_relevantes)

        # Mostrar sugest√µes na interface
        st.subheader("Sugest√µes de Palavras Compostas")
        st.write(", ".join(palavras_compostas_relevantes))

        # Gerar corpus
        for sigla, significado in dict_siglas.items():
            texto_corrigido = re.sub(rf"\({sigla}\)", "", texto_corrigido)
            texto_corrigido = re.sub(rf"\b{sigla}\b", significado, texto_corrigido, flags=re.IGNORECASE)
            total_siglas += 1

        for termo, substituto in dict_compostos.items():
            if termo in texto_corrigido:
                texto_corrigido = re.sub(rf"\b{termo}\b", substituto, texto_corrigido, flags=re.IGNORECASE)
                total_compostos += 1

        for char in caracteres_especiais:
            count = texto_corrigido.count(char)
            if count:
                # Se o caractere for '%' n√£o substitu√≠mos por '_', apenas removemos
                if char == "%":
                    texto_corrigido = texto_corrigido.replace(char, "")
                else:
                    texto_corrigido = texto_corrigido.replace(char, "_")
                contagem_caracteres[char] += count
                total_remocoes += count

        texto_corrigido = re.sub(r"\s+", " ", texto_corrigido.strip())

        metadata = f"**** *ID_{id_val}"

        corpus_final += f"{metadata}\n{texto_corrigido}\n"

    else:
        for _, row in df_textos.iterrows():
            texto = str(row.get("textos selecionados", ""))
            id_val = row.get("id", "")
            if not texto.strip():
                continue

            texto_corrigido = texto.lower()
            texto_corrigido = converter_numeros_por_extenso(texto_corrigido)
            texto_corrigido = processar_palavras_com_se(texto_corrigido)
            texto_corrigido = processar_pronomes_pospostos(texto_corrigido)
            total_textos += 1

            # Sugerir palavras compostas e filtrar stopwords
            palavras_compostas_relevantes = sugerir_palavras_compostas_e_siglas(texto_corrigido, stopwords)
            total_compostos += len(palavras_compostas_relevantes)

            for sigla, significado in dict_siglas.items():
                texto_corrigido = re.sub(rf"\({sigla}\)", "", texto_corrigido)
                texto_corrigido = re.sub(rf"\b{sigla}\b", significado, texto_corrigido, flags=re.IGNORECASE)
                total_siglas += 1

            for termo, substituto in dict_compostos.items():
                if termo in texto_corrigido:
                    texto_corrigido = re.sub(rf"\b{termo}\b", substituto, texto_corrigido, flags=re.IGNORECASE)
                    total_compostos += 1

            for char in caracteres_especiais:
                count = texto_corrigido.count(char)
                if count:
                    # Se o caractere for '%' n√£o substitu√≠mos por '_', apenas removemos
                    if char == "%":
                        texto_corrigido = texto_corrigido.replace(char, "")
                    else:
                        texto_corrigido = texto_corrigido.replace(char, "_")
                    contagem_caracteres[char] += count
                    total_remocoes += count

            texto_corrigido = re.sub(r"\s+", " ", texto_corrigido.strip())

            metadata = f"**** *ID_{id_val}"
            for col in row.index:
                if col.lower() not in ["id", "textos selecionados"]:
                    metadata += f" *{col.replace(' ', '_')}_{str(row[col]).replace(' ', '_')}"

            corpus_final += f"{metadata}\n{texto_corrigido}\n"

    estatisticas = f"Textos processados: {total_textos}\n"
    estatisticas += f"Siglas removidas/substitu√≠das: {total_siglas}\n"
    estatisticas += f"Palavras compostas sugeridas: {total_compostos}\n"
    estatisticas += f"Caracteres especiais removidos: {total_remocoes}\n"
    for char, nome in caracteres_especiais.items():
        if contagem_caracteres[char] > 0:
            estatisticas += f" - {nome} ({char}) : {contagem_caracteres[char]}\n"

    return corpus_final, estatisticas

# Lista de stopwords (pode ser expandida conforme necess√°rio)
stopwords = ["de", "a", "o", "as", "os", "e", "em", "para", "com", "por", "que", "na", "no", "da", "do"]

# Interface Streamlit
st.set_page_config(layout="wide")
st.title("Gerador de corpus textual para IRaMuTeQ")

st.markdown("""
### üìå Instru√ß√µes

Esta ferramenta foi desenvolvida para facilitar a gera√ß√£o de corpus textual compat√≠vel com o IRaMuTeQ.

Envie um arquivo do Excel **.xlsx** com a estrutura correta para que o corpus possa ser gerado automaticamente.

Sua planilha deve conter **tr√™s abas (planilhas internas)** com os seguintes nomes e finalidades:

1. **`textos_selecionados`** : cole√ß√£o de textos que ser√£o transformados de acordo com as regras de normaliza√ß√£o.  
2. **`dic_palavras_compostas`** : permite substituir palavras compostas por suas formas normalizadas, garantindo uma maior consist√™ncia no corpus textual gerado.  
3. **`dic_siglas`** : tem a finalidade de expandir siglas para suas formas completas, aumentando a legibilidade e a clareza do texto.
""")

# Caixa de texto para o usu√°rio colar o conte√∫do diretamente
texto_usuario = st.text_area("Coloque seu texto aqui", height=200)

file = st.file_uploader("Ou envie sua planilha preenchida", type=["xlsx"])

if file:
    try:
        xls = pd.ExcelFile(file)
        df_textos = xls.parse("textos_selecionados")
        df_compostos = xls.parse("dic_palavras_compostas")
        df_siglas = xls.parse("dic_siglas")
        df_textos.columns = [col.strip().lower() for col in df_textos.columns]

        if st.button("üöÄ GERAR CORPUS TEXTUAL"):
            corpus, estatisticas = gerar_corpus(df_textos, df_compostos, df_siglas, stopwords, texto_usuario)

            if corpus.strip():
                st.success("Corpus gerado com sucesso!")
                st.download_button("Baixar Corpus", corpus, "corpus.txt", mime="text/plain")
                st.text_area("Estat√≠sticas", estatisticas, height=300)
    except Exception as e:
        st.error(f"Erro ao processar a planilha: {e}")
