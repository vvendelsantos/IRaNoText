import streamlit as st
import pandas as pd
import re
import io
from word2number import w2n
from datetime import datetime
import zipfile
import os

# Configura√ß√µes iniciais
st.set_page_config(layout="wide", page_title="Gerador de Corpus IRaMuTeQ", page_icon="üìö")

# Fun√ß√£o para converter n√∫meros por extenso para algarismos
def converter_numeros_por_extenso(texto):
    unidades = {
        "zero": 0, "dois": 2, "duas": 2, "tr√™s": 3, "quatro": 4, "cinco": 5,
        "seis": 6, "sete": 7, "oito": 8, "nove": 9
    }
    dezenas = {
        "dez": 10, "onze": 11, "doze": 12, "treze": 13, "quatorze": 14, "quinze": 15,
        "dezesseis": 16, "dezessete": 17, "dezoito": 18, "dezenove": 19, "vinte": 20
    }
    centenas = {
        "cem": 100, "cento": 100, "duzentos": 200, "trezentos": 300, "quatrocentos": 400,
        "quinhentos": 500, "seiscentos": 600, "setecentos": 700, "oitocentos": 800, "novecentos": 900
    }
    multiplicadores = {
        "mil": 1000, "milh√£o": 1000000, "milh√µes": 1000000, "bilh√£o": 1000000000,
        "bilh√µes": 1000000000
    }

    def processar_palavra(palavra):
        try:
            return str(w2n.word_to_num(palavra))
        except:
            return palavra

    palavras = texto.split()
    resultado = []
    for palavra in palavras:
        palavra_lower = palavra.lower()
        if palavra_lower in unidades:
            resultado.append(str(unidades[palavra_lower]))
        elif palavra_lower in dezenas:
            resultado.append(str(dezenas[palavra_lower]))
        elif palavra_lower in centenas:
            resultado.append(str(centenas[palavra_lower]))
        elif palavra_lower in multiplicadores:
            resultado.append(str(multiplicadores[palavra_lower]))
        else:
            resultado.append(processar_palavra(palavra))

    return " ".join(resultado)

# Fun√ß√£o para processar palavras compostas com "-se"
def processar_palavras_com_se(texto):
    return re.sub(r"(\b\w+)-se\b", r"se \1", texto)

# Fun√ß√£o para processar pronomes obl√≠quos p√≥s-verbais
def processar_pronomes_pospostos(texto):
    texto = re.sub(r'\b(\w+)-se\b', r'se \1', texto)
    texto = re.sub(r'\b(\w+)-([oa]s?)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)-(lhe|lhes)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)-(me|te|nos|vos)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]?-([oa]s?)\b', r'\2 \1', texto)
    texto = re.sub(r'\b(\w+)[√°√©√≠√≥√∫√¢√™√¥]-(lo|la|los|las)-ia\b', r'\2 \1ia', texto)
    return texto

# Fun√ß√£o para verificar estrutura da planilha
def verificar_estrutura(df_textos, df_compostos, df_siglas):
    erros = []
    
    # Verificar colunas obrigat√≥rias
    if "textos selecionados" not in df_textos.columns.str.lower():
        erros.append("A aba 'textos_selecionados' deve conter a coluna 'textos selecionados'")
    
    if len(df_textos) == 0:
        erros.append("A aba 'textos_selecionados' est√° vazia")
    
    # Verificar se h√° pelo menos uma coluna de metadados al√©m do texto
    if len(df_textos.columns) < 2:
        erros.append("Adicione pelo menos uma coluna de metadados (ex: id, autor, etc.) na aba 'textos_selecionados'")
    
    return erros

# Fun√ß√£o para gerar relat√≥rio detalhado
def gerar_relatorio(total_textos, total_siglas, total_compostos, total_remocoes, contagem_caracteres, tempo_processamento):
    relatorio = f"RELAT√ìRIO DE PROCESSAMENTO - {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n"
    relatorio += "="*50 + "\n"
    relatorio += f"üìù Textos processados: {total_textos}\n"
    relatorio += f"üî§ Siglas expandidas: {total_siglas}\n"
    relatorio += f"üîó Palavras compostas normalizadas: {total_compostos}\n"
    relatorio += f"‚ùå Caracteres especiais removidos: {total_remocoes}\n\n"
    
    relatorio += "üìä Detalhe de caracteres especiais removidos:\n"
    for char, nome in caracteres_especiais.items():
        if contagem_caracteres[char] > 0:
            relatorio += f" - {nome} ({char}): {contagem_caracteres[char]}\n"
    
    relatorio += f"\n‚è± Tempo de processamento: {tempo_processamento:.2f} segundos\n"
    return relatorio

# Fun√ß√£o principal
def gerar_corpus(df_textos, df_compostos, df_siglas):
    inicio = datetime.now()
    
    dict_compostos = {
        str(row["Palavra composta"]).lower(): str(row["Palavra normalizada"]).lower()
        for _, row in df_compostos.iterrows()
        if pd.notna(row["Palavra composta"]) and pd.notna(row["Palavra normalizada"])
    }

    dict_siglas = {
        str(row["Sigla"]).lower(): str(row["Significado"])
        for _, row in df_siglas.iterrows()
        if pd.notna(row["Sigla"]) and pd.notna(row["Significado"])
    }

    global caracteres_especiais
    caracteres_especiais = {
        "-": "H√≠fen", ";": "Ponto e v√≠rgula", '"': "Aspas duplas", "'": "Aspas simples",
        "‚Ä¶": "Retic√™ncias", "‚Äì": "Travess√£o", "(": "Par√™ntese esquerdo", ")": "Par√™ntese direito",
        "/": "Barra", "%": "Porcentagem", "&": "E comercial", "@": "Arroba",
        "#": "Cerquilha", "*": "Asterisco", "+": "Mais", "=": "Igual",
        "<": "Menor que", ">": "Maior que", "[": "Colchete esquerdo", "]": "Colchete direito",
        "{": "Chave esquerda", "}": "Chave direita", "\\": "Barra invertida", "|": "Barra vertical",
        "^": "Circunflexo", "~": "Til", "`": "Acento grave"
    }
    
    contagem_caracteres = {k: 0 for k in caracteres_especiais}
    total_textos = 0
    total_siglas = 0
    total_compostos = 0
    total_remocoes = 0
    corpus_final = ""
    textos_originais = []
    textos_processados = []

    for _, row in df_textos.iterrows():
        texto = str(row.get("textos selecionados", ""))
        id_val = row.get("id", "")
        if not texto.strip():
            continue

        texto_original = texto
        texto_corrigido = texto.lower()
        texto_corrigido = converter_numeros_por_extenso(texto_corrigido)
        texto_corrigido = processar_palavras_com_se(texto_corrigido)
        texto_corrigido = processar_pronomes_pospostos(texto_corrigido)
        total_textos += 1

        for sigla, significado in dict_siglas.items():
            texto_corrigido = re.sub(rf"\({sigla}\)", "", texto_corrigido)
            texto_corrigido = re.sub(rf"\b{sigla}\b", significado, texto_corrigido, flags=re.IGNORECASE)
            total_siglas += 1

        for termo, substituto in dict_compostos.items():
            if termo in texto_corrigido:
                texto_corrigido = re.sub(rf"\b{termo}\b", substituto, texto_corrigido, flags=re.IGNORECASE)
                total_compostos += 1

        for char in caracteres_especiais:
            count = texto_corrigido.count(char)
            if count:
                if char == "%":
                    texto_corrigido = texto_corrigido.replace(char, "")
                else:
                    texto_corrigido = texto_corrigido.replace(char, "_")
                contagem_caracteres[char] += count
                total_remocoes += count

        texto_corrigido = re.sub(r"\s+", " ", texto_corrigido.strip())

        metadata = f"**** *ID_{id_val}"
        for col in row.index:
            if col.lower() not in ["id", "textos selecionados"]:
                metadata += f" *{col.replace(' ', '_')}_{str(row[col]).replace(' ', '_')}"

        corpus_final += f"{metadata}\n{texto_corrigido}\n"
        textos_originais.append(f"=== ID: {id_val} ===\n{texto_original}\n")
        textos_processados.append(f"=== ID: {id_val} ===\n{texto_corrigido}\n")

    tempo_processamento = (datetime.now() - inicio).total_seconds()
    
    estatisticas = gerar_relatorio(total_textos, total_siglas, total_compostos, 
                                 total_remocoes, contagem_caracteres, tempo_processamento)
    
    return corpus_final, estatisticas, "\n".join(textos_originais), "\n".join(textos_processados)

# Interface Streamlit
def main():
    st.title("üìö Gerador de corpus textual para IRaMuTeQ")
    
    # Menu lateral
    st.sidebar.title("Configura√ß√µes")
    opcao_visualizacao = st.sidebar.radio("Modo de visualiza√ß√£o:", ["Completo", "Simplificado"])
    mostrar_instrucoes = st.sidebar.checkbox("Mostrar instru√ß√µes", value=True)
    
    # Abas principais
    tab1, tab2, tab3 = st.tabs(["üì§ Upload de Arquivos", "‚öôÔ∏è Configura√ß√µes Avan√ßadas", "‚ÑπÔ∏è Sobre"])
    
    with tab1:
        if mostrar_instrucoes:
            st.markdown("""
            ### üìå Instru√ß√µes

            Esta ferramenta foi desenvolvida para facilitar a gera√ß√£o de corpus textual compat√≠vel com o IRaMuTeQ.

            Envie um arquivo do Excel **.xlsx** com a estrutura correta para que o corpus possa ser gerado automaticamente.

            Sua planilha deve conter **tr√™s abas (planilhas internas)** com os seguintes nomes e finalidades:

            1. **`textos_selecionados`** : cole√ß√£o de textos que ser√£o transformados de acordo com as regras de normaliza√ß√£o.  
            2. **`dic_palavras_compostas`** : permite substituir palavras compostas por suas formas normalizadas.  
            3. **`dic_siglas`** : tem a finalidade de expandir siglas para suas formas completas.
            """)

        with open("gerar_corpus_iramuteq.xlsx", "rb") as exemplo:
            st.download_button(
                label="üì• Baixar modelo de planilha",
                data=exemplo,
                file_name="gerar_corpus_iramuteq.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        file = st.file_uploader("Envie sua planilha preenchida", type=["xlsx"], key="file_uploader")

        if file:
            try:
                xls = pd.ExcelFile(file)
                required_sheets = ["textos_selecionados", "dic_palavras_compostas", "dic_siglas"]
                
                # Verificar se todas as abas necess√°rias est√£o presentes
                missing_sheets = [sheet for sheet in required_sheets if sheet not in xls.sheet_names]
                if missing_sheets:
                    st.error(f"Faltam as seguintes abas na planilha: {', '.join(missing_sheets)}")
                    return
                
                df_textos = xls.parse("textos_selecionados")
                df_compostos = xls.parse("dic_palavras_compostas")
                df_siglas = xls.parse("dic_siglas")
                df_textos.columns = [col.strip().lower() for col in df_textos.columns]

                # Verificar estrutura
                erros = verificar_estrutura(df_textos, df_compostos, df_siglas)
                if erros:
                    for erro in erros:
                        st.error(erro)
                    return

                # Visualiza√ß√£o pr√©via dos dados
                with st.expander("üîç Visualizar dados carregados"):
                    st.subheader("Textos Selecionados (amostra)")
                    st.dataframe(df_textos.head())
                    
                    st.subheader("Palavras Compostas (amostra)")
                    st.dataframe(df_compostos.head())
                    
                    st.subheader("Siglas (amostra)")
                    st.dataframe(df_siglas.head())

                if st.button("üöÄ Gerar Corpus Textual", key="generate_button"):
                    with st.spinner("Processando textos, aguarde..."):
                        corpus, estatisticas, originais, processados = gerar_corpus(df_textos, df_compostos, df_siglas)

                    if corpus.strip():
                        st.success("‚úÖ Corpus gerado com sucesso!")
                        
                        # Exibir estat√≠sticas
                        with st.expander("üìä Estat√≠sticas detalhadas"):
                            st.text(estatisticas)
                        
                        # Criar arquivos ZIP
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, 'a', zipfile.ZIP_DEFLATED, False) as zip_file:
                            zip_file.writestr("corpus_IRaMuTeQ.txt", corpus.encode('utf-8'))
                            zip_file.writestr("textos_originais.txt", originais.encode('utf-8'))
                            zip_file.writestr("textos_processados.txt", processados.encode('utf-8'))
                            zip_file.writestr("relatorio_processamento.txt", estatisticas.encode('utf-8'))
                        
                        # Bot√µes de download
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.download_button(
                                label="üìÑ Baixar Corpus",
                                data=corpus.encode('utf-8'),
                                file_name="corpus_IRaMuTeQ.txt",
                                mime="text/plain"
                            )
                        with col2:
                            st.download_button(
                                label="üì¶ Baixar Tudo (ZIP)",
                                data=zip_buffer.getvalue(),
                                file_name="corpus_completo.zip",
                                mime="application/zip"
                            )
                        with col3:
                            st.download_button(
                                label="üìä Baixar Relat√≥rio",
                                data=estatisticas.encode('utf-8'),
                                file_name="relatorio_processamento.txt",
                                mime="text/plain"
                            )
                        
                        # Visualiza√ß√£o do corpus
                        with st.expander("üëÄ Visualizar Corpus Gerado"):
                            st.text(corpus[:5000] + ("..." if len(corpus) > 5000 else ""))
                    else:
                        st.warning("‚ö†Ô∏è Nenhum texto processado. Verifique os dados da planilha.")

            except Exception as e:
                st.error(f"‚ùå Erro ao processar o arquivo: {str(e)}")
                st.error("Verifique a estrutura da planilha conforme o modelo fornecido.")

    with tab2:
        st.header("Configura√ß√µes Avan√ßadas")
        
        st.subheader("Caracteres Especiais")
        st.write("Configure quais caracteres especiais devem ser removidos ou substitu√≠dos:")
        
        # Editar lista de caracteres especiais
        caracteres_editaveis = st.text_area(
            "Lista de caracteres especiais (um por linha, formato: caractere=descri√ß√£o)",
            value="\n".join([f"{k}={v}" for k, v in caracteres_especiais.items()]),
            height=200
        )
        
        st.subheader("Op√ß√µes de Processamento")
        remover_porcentagem = st.checkbox("Remover s√≠mbolo de porcentagem (%)", value=True)
        substituir_hifen = st.checkbox("Substituir h√≠fen por underscore (_)", value=True)
        
        st.subheader("Metadados")
        incluir_data = st.checkbox("Incluir data de processamento nos metadados", value=True)
        prefixo_metadados = st.text_input("Prefixo para metadados", value="****")
    
    with tab3:
        st.header("Sobre o Projeto")
        st.markdown("""
        ### üìö Gerador de Corpus para IRaMuTeQ
        
        Esta ferramenta foi desenvolvida para auxiliar pesquisadores na prepara√ß√£o de corpora textuais 
        para an√°lise no software IRaMuTeQ, realizando automaticamente:
        
        - Normaliza√ß√£o de textos
        - Expans√£o de siglas
        - Substitui√ß√£o de palavras compostas
        - Remo√ß√£o de caracteres especiais
        - Gera√ß√£o de metadados
        
        ### üë®‚Äçüíª Autor
        
        **Jos√© Wendel dos Santos**  
        Doutorando em Letras - Universidade Federal de Sergipe (UFS)  
        ‚úâÔ∏è eng.wendel@gmail.com  
        üîó [Lattes](http://lattes.cnpq.br/1234567890123456)
        
        ### üìÑ Licen√ßa
        
        Este software √© distribu√≠do sob a licen√ßa MIT.
        """)

if __name__ == "__main__":
    main()
